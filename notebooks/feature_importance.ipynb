{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7a09d8-570b-401f-a972-35f80d1f7457",
   "metadata": {},
   "source": [
    "#### Include source package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a339b7a-4d18-4e45-a609-e6f1afb4a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to the project directory\n",
    "%cd ..\n",
    "# working directory should be ../pdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28077eec-1441-4b1b-9b45-3dd1a68bdd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath('src')\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e111e1",
   "metadata": {},
   "source": [
    "#### Load preprocessed train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8322f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdi.data.data_preparation import DataPreparation\n",
    "from pdi.data.types import Split\n",
    "from pdi.config import Config\n",
    "from pdi.constants import PART_NAME_TO_TARGET_CODE, TARGET_CODE_TO_PART_NAME\n",
    "import json\n",
    "\n",
    "RUN_DIR_PATH = \"results/attention_hyperparameter_tuning/kaon/run_23\"\n",
    "target_code = PART_NAME_TO_TARGET_CODE[\"kaon\"]\n",
    "\n",
    "with open(f\"{RUN_DIR_PATH}/config.json\", 'r') as f:\n",
    "    config_data = json.load(f)\n",
    "config = Config.from_dict(config_data)\n",
    "\n",
    "# If you override device for explaining do it such a way\n",
    "config.training.device = \"cpu\"\n",
    "\n",
    "data_prep = DataPreparation(config.data, config.sim_dataset_paths, config.seed)\n",
    "groups = data_prep.get_prepared_data([Split.TEST])[Split.TEST]\n",
    "print(groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88509d9205ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pdi.models import build_model\n",
    "\n",
    "model = build_model(config.model, group_ids=list(groups.keys()))\n",
    "dirpath = os.path.join(RUN_DIR_PATH, \"model_weights\")\n",
    "weights_path = os.path.join(dirpath, \"best.pt\")\n",
    "model.load_state_dict(torch.load(weights_path, weights_only=True, map_location=config.training.device))\n",
    "with open(os.path.join(dirpath, f\"metadata.json\"), \"r\") as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "threshold = metadata[\"threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c810789327aeaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for model, explainers don't allow passing tensors\n",
    "def predict(input_data):\n",
    "    new_in = torch.tensor(input_data).to(config.training.device)\n",
    "    return model(new_in).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e423cc73a71c67",
   "metadata": {},
   "source": [
    "## Model explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723cf662dcdaa72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdi.data.data_exploration import explain_model, plot_and_save_beeswarm\n",
    "from pdi.data.constants import COLUMNS_FOR_TRAINING\n",
    "from pdi.data.group_id_helpers import group_id_to_detectors_available\n",
    "from pdi.data.types import InputTarget\n",
    "\n",
    "batch_size = 16 # for bigger number of entries kernel crashes, so here data is split into batches\n",
    "batches = 50\n",
    "hide_progress_bars = False\n",
    "\n",
    "cols = COLUMNS_FOR_TRAINING\n",
    "\n",
    "for key, input_target_unstandardized in groups.items():\n",
    "    group_input = input_target_unstandardized[InputTarget.INPUT]\n",
    "    detectors = group_id_to_detectors_available(key)\n",
    "    detectors = [d.name for d in detectors]\n",
    "    label = \"_\".join(detectors)\n",
    "    print(label)\n",
    "    \n",
    "    result, data_count = explain_model(predict, group_input, batch_size, batches, hide_progress_bars)\n",
    "    result.feature_names = cols\n",
    "\n",
    "    save_dir = f\"{RUN_DIR_PATH}/feature_importance\"\n",
    "    \n",
    "    file_name = f\"/{label}\"\n",
    "    title = f\"{label}: {TARGET_CODE_TO_PART_NAME[target_code]}, entries: {data_count}\"\n",
    "    plot_and_save_beeswarm(result, save_dir, file_name, title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
