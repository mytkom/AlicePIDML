{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mytkom/Documents/alice/pdi\n"
     ]
    }
   ],
   "source": [
    "# switch to the project directory\n",
    "%cd ../..\n",
    "# working directory should be ../pdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath('src')\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use this notebook?\n",
    "1. Train models with desired configs and use `scripts` subdirectory scripts to achieve that.\n",
    "2. Fill `MODELS` dictionary with paths to the results dir of the run and name it appropriately as in dictionary element key.\n",
    "3. Run desired plot/table generation cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdi.constants import PART_NAME_TO_TARGET_CODE\n",
    "\n",
    "MODELS = {\n",
    "    \"alpha=0\": \"results/attention_dann_hyperparameter_tuning/best_run_alpha_0\",\n",
    "    \"alpha=0.15\": \"results/attention_dann_hyperparameter_tuning/sweep_118f437672375fa45c5e417106c304a1/kaon/run_25\",\n",
    "}\n",
    "target_code = PART_NAME_TO_TARGET_CODE[\"kaon\"]\n",
    "\n",
    "save_dir = \"reports\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataPreparation] Calculating input_paths + configuration checksum:\n",
      "[DataPreparation] \tresulting checksum: 0858460c6963f0b5c7dce050440ffd05\n",
      "[DataPreparation] Successfuly loaded preprocessed data! No need for from scratch preparation.\n",
      "[DataPreparation] Calculating input_paths + configuration checksum:\n",
      "[DataPreparation] \tresulting checksum: cb3638b8f27a952941ad38bdb37f4570\n",
      "[DataPreparation] Successfuly loaded preprocessed data! No need for from scratch preparation.\n",
      "Model attention_dann has been initialized:\n",
      "\tNumber of trainable parameters: 463426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Simulated Data: 100%|██████████| 290/290 [02:09<00:00,  2.23it/s]\n",
      "Processing Experimental Data: 100%|██████████| 356/356 [03:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataPreparation] Calculating input_paths + configuration checksum:\n",
      "[DataPreparation] \tresulting checksum: 0858460c6963f0b5c7dce050440ffd05\n",
      "[DataPreparation] Successfuly loaded preprocessed data! No need for from scratch preparation.\n",
      "[DataPreparation] Calculating input_paths + configuration checksum:\n",
      "[DataPreparation] \tresulting checksum: cb3638b8f27a952941ad38bdb37f4570\n",
      "[DataPreparation] Successfuly loaded preprocessed data! No need for from scratch preparation.\n",
      "Model attention_dann has been initialized:\n",
      "\tNumber of trainable parameters: 463426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Simulated Data: 100%|██████████| 290/290 [02:11<00:00,  2.21it/s]\n",
      "Processing Experimental Data: 100%|██████████| 356/356 [03:04<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import cast\n",
    "from pdi.config import Config\n",
    "from pdi.engines import build_engine, DomainAdaptationEngine\n",
    "from pdi.results_and_metrics import TestResults\n",
    "from pdi.data.data_preparation import DataPreparation\n",
    "from pdi.data.types import Split\n",
    "\n",
    "sim_data_prep: DataPreparation | None = None\n",
    "exp_data_prep: DataPreparation | None = None\n",
    "checksums = set()\n",
    "test_results: dict[str, tuple[list, list]] = {}\n",
    "for k, v in MODELS.items():\n",
    "    with open(f\"{v}/config.json\", 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "    config = Config.from_dict(config_data)\n",
    "    config.training.device = \"cpu\"\n",
    "    config.validation.batch_size = 2048\n",
    "    config.validation.num_workers = 2\n",
    "    engine = build_engine(config, target_code, base_dir=v)\n",
    "    engine = cast(DomainAdaptationEngine, engine)\n",
    "    current_data_prep = engine.get_data_prep()\n",
    "    if sim_data_prep is None or exp_data_prep is None:\n",
    "        sim_data_prep = current_data_prep[0]\n",
    "        exp_data_prep = current_data_prep[1]\n",
    "    checksums.add(sim_data_prep._inputs_checksum + exp_data_prep._inputs_checksum)\n",
    "    test_results[k] = engine.feature_extraction(model_dirpath=v)\n",
    "\n",
    "if len(checksums) > 1:\n",
    "    raise RuntimeError(\"You shouldn't compare models trained on different datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing key: alpha=0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "SEED = 1401\n",
    "\n",
    "def compute_mmd(X, Y, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Compute the Maximum Mean Discrepancy (MMD) between two datasets X and Y.\n",
    "    Uses the RBF kernel with the specified gamma parameter.\n",
    "    \"\"\"\n",
    "    XX = rbf_kernel(X, X, gamma=gamma)\n",
    "    YY = rbf_kernel(Y, Y, gamma=gamma)\n",
    "    XY = rbf_kernel(X, Y, gamma=gamma)\n",
    "    mmd = XX.mean() + YY.mean() - 2 * XY.mean()\n",
    "    return mmd\n",
    "\n",
    "# Iterate over all test results\n",
    "for key, (simulated_features, experimental_features) in test_results.items():\n",
    "    print(f\"Processing key: {key}\")\n",
    "    \n",
    "    # Subsample the datasets\n",
    "    np.random.seed(SEED)\n",
    "    sim_sample_size = min(20000, len(simulated_features))\n",
    "    exp_sample_size = min(20000, len(experimental_features))\n",
    "\n",
    "    simulated_sample = simulated_features[np.random.choice(len(simulated_features), sim_sample_size, replace=False)]\n",
    "    experimental_sample = experimental_features[np.random.choice(len(experimental_features), exp_sample_size, replace=False)]\n",
    "\n",
    "    combined_features = np.vstack((simulated_sample, experimental_sample))\n",
    "    labels = np.array([0] * len(simulated_sample) + [1] * len(experimental_sample))\n",
    "\n",
    "    # t-SNE visualization\n",
    "    tsne = TSNE(n_components=2, random_state=SEED, perplexity=30, n_iter=1000)\n",
    "    tsne_results = tsne.fit_transform(combined_features)\n",
    "\n",
    "    sim_tsne = tsne_results[:len(simulated_sample)]\n",
    "    exp_tsne = tsne_results[len(simulated_sample):]\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(sim_tsne[:, 0], sim_tsne[:, 1], c='blue', label='Simulated', alpha=0.6)\n",
    "    plt.scatter(exp_tsne[:, 0], exp_tsne[:, 1], c='orange', label='Experimental', alpha=0.6)\n",
    "    plt.title(f't-SNE Visualization of Subsampled Simulated and Experimental Features ({key})')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Normalized diff histogram\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    xmin = -100\n",
    "    xmax = 100\n",
    "    ymin = -100\n",
    "    ymax = 100\n",
    "\n",
    "    # Compute 2D histograms for both datasets\n",
    "    hist_sim, xedges, yedges = np.histogram2d(sim_tsne[:, 0], sim_tsne[:, 1], bins=200, range=[[xmin, xmax], [ymin, ymax]])\n",
    "    hist_exp, _, _ = np.histogram2d(exp_tsne[:, 0], exp_tsne[:, 1], bins=200, range=[[xmin, xmax], [ymin, ymax]])\n",
    "\n",
    "    # Calculate the difference between the two histograms\n",
    "    hist_diff = hist_sim - hist_exp\n",
    "\n",
    "    # Normalize the difference to the range [-1, 1]\n",
    "    max_abs_diff = np.max(np.abs(hist_diff))\n",
    "    hist_diff_normalized = hist_diff / max_abs_diff\n",
    "\n",
    "    # Plot the normalized difference as a 2D histogram\n",
    "    im = plt.imshow(hist_diff_normalized.T, origin='lower', extent=[xmin, xmax, ymin, ymax], cmap='coolwarm', aspect='auto')\n",
    "\n",
    "    plt.title(f'Normalized Difference of 2D Histograms ({key})')\n",
    "    plt.xlabel('t-SNE Component 1')\n",
    "    plt.ylabel('t-SNE Component 2')\n",
    "\n",
    "    # Add a colorbar with an extended label\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label('Normalized Difference [-1, 1]\\n(Positive: sim > exp, Negative: exp > sim)')\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = {}\n",
    "\n",
    "    # Kolmogorov-Smirnov (KS)\n",
    "    ks_distances = []\n",
    "    for i in range(simulated_sample.shape[1]):\n",
    "        ks_stat, _ = ks_2samp(simulated_sample[:, i], experimental_sample[:, i])\n",
    "        ks_distances.append(ks_stat)\n",
    "    metrics['Kolmogorov-Smirnov Mean'] = np.mean(ks_distances)\n",
    "    metrics['Kolmogorov-Smirnov Max'] = np.max(ks_distances)\n",
    "\n",
    "    # Maximum Mean Discrepancy (MMD)\n",
    "    mmd_value = compute_mmd(simulated_sample, experimental_sample, gamma=1.0)\n",
    "    metrics['Maximum Mean Discrepancy (MMD)'] = mmd_value\n",
    "\n",
    "    # Save metrics to CSV\n",
    "    metrics_df = pd.DataFrame([metrics])\n",
    "    output_path = f'{MODELS[key]}/two_sample_test_metrics.csv'\n",
    "    metrics_df.to_csv(output_path, index=False)\n",
    "    print(f\"Two-sample test metrics for key '{key}' calculated and saved to '{output_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
