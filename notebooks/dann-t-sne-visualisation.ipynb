{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to the project directory\n",
    "%cd ..\n",
    "# working directory should be ../pdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath('src')\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to use this notebook?\n",
    "1. Train models with desired configs and use `scripts` subdirectory scripts to achieve that.\n",
    "2. Fill `MODELS` dictionary with paths to the results dir of the run and name it appropriately as in dictionary element key.\n",
    "3. Run desired plot/table generation cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdi.constants import PART_NAME_TO_TARGET_CODE\n",
    "\n",
    "MODELS = {\n",
    "    \"Attention\": \"results/attention_dann_kaon_alpha_0_1\",\n",
    "}\n",
    "target_code = PART_NAME_TO_TARGET_CODE[\"kaon\"]\n",
    "\n",
    "save_dir = \"reports\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import cast\n",
    "from pdi.config import Config\n",
    "from pdi.engines import build_engine, DomainAdaptationEngine\n",
    "from pdi.results_and_metrics import TestResults\n",
    "from pdi.data.data_preparation import DataPreparation\n",
    "from pdi.data.types import Split\n",
    "\n",
    "sim_data_prep: DataPreparation | None = None\n",
    "exp_data_prep: DataPreparation | None = None\n",
    "checksums = set()\n",
    "test_results: dict[str, tuple[list, list]] = {}\n",
    "for k, v in MODELS.items():\n",
    "    with open(f\"{v}/config.json\", 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "    config = Config.from_dict(config_data)\n",
    "    config.training.device = \"cpu\"\n",
    "    config.validation.batch_size = 2048\n",
    "    config.validation.num_workers = 2\n",
    "    engine = build_engine(config, target_code, base_dir=v)\n",
    "    engine = cast(DomainAdaptationEngine, engine)\n",
    "    current_data_prep = engine.get_data_prep()\n",
    "    if sim_data_prep is None or exp_data_prep is None:\n",
    "        sim_data_prep = current_data_prep[0]\n",
    "        exp_data_prep = current_data_prep[1]\n",
    "    checksums.add(sim_data_prep._inputs_checksum + exp_data_prep._inputs_checksum)\n",
    "    test_results[k] = engine.feature_extraction(model_dirpath=v)\n",
    "\n",
    "if len(checksums) > 1:\n",
    "    raise RuntimeError(\"You shouldn't compare models trained on different datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results[\"Attention\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "simulated_features, experimental_features = test_results[\"Attention\"]\n",
    "\n",
    "# Subsample the datasets\n",
    "np.random.seed(42)\n",
    "sim_sample_size = min(20000, len(simulated_features))\n",
    "exp_sample_size = min(20000, len(experimental_features))\n",
    "\n",
    "simulated_sample = simulated_features[np.random.choice(len(simulated_features), sim_sample_size, replace=False)]\n",
    "experimental_sample = experimental_features[np.random.choice(len(experimental_features), exp_sample_size, replace=False)]\n",
    "\n",
    "combined_features = np.vstack((simulated_sample, experimental_sample))\n",
    "\n",
    "labels = np.array([0] * len(simulated_sample) + [1] * len(experimental_sample))\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(combined_features)\n",
    "\n",
    "sim_tsne = tsne_results[:len(simulated_sample)]\n",
    "exp_tsne = tsne_results[len(simulated_sample):]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(sim_tsne[:, 0], sim_tsne[:, 1], c='blue', label='Simulated', alpha=0.6)\n",
    "plt.scatter(exp_tsne[:, 0], exp_tsne[:, 1], c='orange', label='Experimental', alpha=0.6)\n",
    "plt.title('t-SNE Visualization of Subsampled Simulated and Experimental Features')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def compute_mmd(X, Y, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Compute the Maximum Mean Discrepancy (MMD) between two datasets X and Y.\n",
    "    Uses the RBF kernel with the specified gamma parameter.\n",
    "    \"\"\"\n",
    "    XX = rbf_kernel(X, X, gamma=gamma)\n",
    "    YY = rbf_kernel(Y, Y, gamma=gamma)\n",
    "    XY = rbf_kernel(X, Y, gamma=gamma)\n",
    "    mmd = XX.mean() + YY.mean() - 2 * XY.mean()\n",
    "    return mmd\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "# Kolmogorov-Smirnov (KS)\n",
    "ks_distances = []\n",
    "for i in range(simulated_sample.shape[1]):\n",
    "    ks_stat, _ = ks_2samp(simulated_sample[:, i], experimental_sample[:, i])\n",
    "    ks_distances.append(ks_stat)\n",
    "metrics['Kolmogorov-Smirnov Mean'] = np.mean(ks_distances)\n",
    "metrics['Kolmogorov-Smirnov Max'] = np.max(ks_distances)\n",
    "\n",
    "# Maximum Mean Discrepancy (MMD)\n",
    "mmd_value = compute_mmd(simulated_sample, experimental_sample, gamma=1.0)\n",
    "metrics['Maximum Mean Discrepancy (MMD)'] = mmd_value\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df = pd.DataFrame([metrics])\n",
    "print(metrics_df)\n",
    "metrics_df.to_csv(f'{MODELS[\"Attention\"]}/two_sample_test_metrics.csv', index=False)\n",
    "\n",
    "print(\"Two-sample test metrics calculated and saved to 'two_sample_test_metrics.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
