{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misclassification Analysis\n",
    "\n",
    "Compare your trained model to nSigma based method on scatterplots with TPC Signal and Beta to better understand, where model is working poorly and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to the project directory\n",
    "%cd ..\n",
    "# working directory should be ../pdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath('src')\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdi.constants import PART_NAME_TO_TARGET_CODE\n",
    "\n",
    "MODEL_BASE_DIR = \"results/attention_dann_hyperparameter_tuning/sweep_118f437672375fa45c5e417106c304a1/kaon/run_25\"\n",
    "target_code = PART_NAME_TO_TARGET_CODE[\"kaon\"]\n",
    "\n",
    "save_dir = MODEL_BASE_DIR\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pdi.config import Config\n",
    "from pdi.engines import build_engine\n",
    "from pdi.results_and_metrics import TestResults\n",
    "from pdi.data.data_preparation import DataPreparation\n",
    "from pdi.data.types import Split\n",
    "\n",
    "test_results: dict[str, TestResults] = {}\n",
    "\n",
    "with open(f\"{MODEL_BASE_DIR}/config.json\", 'r') as f:\n",
    "    config_data = json.load(f)\n",
    "config = Config.from_dict(config_data)\n",
    "config.training.device = \"cpu\"\n",
    "engine = build_engine(config, target_code, base_dir=MODEL_BASE_DIR)\n",
    "data_prep = engine.get_data_prep()[0]\n",
    "test_results[\"Model\"] = engine.test(model_dirpath=MODEL_BASE_DIR)\n",
    "\n",
    "# test_results[\"nSigma < 3.0\"] = data_prep.get_nsigma_test_results(target_code, threshold_unscaled=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Unwrapped and Unstandardized Test Split Data as a DataFrame\n",
    "The test split data is explicitly obtained from the `CombinedDataLoader` to ensure consistency. Only the `CombinedDataLoader` has the knowledge of how to unwrap itself, and it will raise errors if the operation cannot be performed. While this could also be achieved by adding an additional method in the `DataPreparation` class, doing so would require `DataPreparation` to understand the internal structure of the `CombinedDataLoader`. This approach would also necessitate updates to `DataPreparation` whenever changes are made to the `CombinedDataLoader`. Therefore, the current approach is preferred for maintaining separation of concerns and avoiding unnecessary dependencies. It is also thousands times faster than iterating over and over dataloader and concatenating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = data_prep.create_dataloaders(\n",
    "    {\n",
    "        Split.TEST: 1 # not used\n",
    "    },\n",
    "    {\n",
    "        Split.TEST: 1 # not used\n",
    "    },\n",
    "    False, False)[Split.TEST]\n",
    "\n",
    "test_data_unwrapped = test_dl.unwrap()\n",
    "print(test_data_unwrapped.shape)\n",
    "test_data_unwrapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pdi.data.data_exploration import generate_figure_thumbnails_from_iterator, plot_feature_combinations\n",
    "from IPython.display import display\n",
    "from pdi.data.constants import TARGET_COLUMN\n",
    "\n",
    "features_to_plot = [(\"fP\", \"fTPCSignal\"), (\"fP\", \"fTRDPattern\"), (\"fP\", \"fBeta\")]\n",
    "saved_dataframes = {}  # Dictionary to store DataFrames\n",
    "\n",
    "def generate_scatterplots(unwrapped_dl_df: pd.DataFrame, test_results: TestResults, features, save_dir, key):\n",
    "    \"\"\"Generate and save scatterplots for different conditions.\"\"\"\n",
    "    is_desired_particle = unwrapped_dl_df[TARGET_COLUMN] == test_results.target_code\n",
    "    selected = test_results.test_metrics.binary_predictions == 1\n",
    "\n",
    "    # Conditions are conditions for misclassified observation, not the other way around\n",
    "    scatterplot_configs = [\n",
    "        {\n",
    "            \"subdir\": \"all_observations\",\n",
    "            \"data\": unwrapped_dl_df,\n",
    "            \"condition\": ((is_desired_particle & ~selected) | (~is_desired_particle & selected)),\n",
    "            \"legend\": (\"Correct prediction\", \"Incorrect prediction\"),\n",
    "            \"title\": f\"Scatter of {{feature1}} vs {{feature2}} for all observations in {key}\"\n",
    "        },\n",
    "        {\n",
    "            \"subdir\": \"target_observations\",\n",
    "            \"data\": unwrapped_dl_df[is_desired_particle],\n",
    "            \"condition\": ~selected[is_desired_particle],\n",
    "            \"legend\": (\"Correct prediction\", \"Incorrect prediction\"),\n",
    "            \"title\": f\"Scatter of {{feature1}} vs {{feature2}} for target observations in {key}\"\n",
    "        },\n",
    "        {\n",
    "            \"subdir\": \"non_target_observations\",\n",
    "            \"data\": unwrapped_dl_df[~is_desired_particle],\n",
    "            \"condition\": selected[~is_desired_particle],\n",
    "            \"legend\": (\"Correct prediction\", \"Incorrect prediction\"),\n",
    "            \"title\": f\"Scatter of {{feature1}} vs {{feature2}} for non-target observations in {key}\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for config in scatterplot_configs:\n",
    "        save_subdir = os.path.join(save_dir, config[\"subdir\"])\n",
    "        os.makedirs(save_subdir, exist_ok=True)\n",
    "        html_element = generate_figure_thumbnails_from_iterator(\n",
    "            plot_feature_combinations(\n",
    "                config[\"data\"], features, config[\"condition\"],\n",
    "                condition_legend=config[\"legend\"],\n",
    "                title_template=config[\"title\"],\n",
    "                log_scale_y=True,\n",
    "            ),\n",
    "            save_subdir\n",
    "        )\n",
    "        display(html_element)\n",
    "\n",
    "# Generate scatterplots for each DataFrame\n",
    "for key, ts in test_results.items():\n",
    "    save_subdir = os.path.join(save_dir, key)\n",
    "    generate_scatterplots(test_data_unwrapped, ts, features_to_plot, save_subdir, key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
